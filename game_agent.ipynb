{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load game_agent.py\n",
    "\"\"\"Finish all TODO items in this file to complete the isolation project, then\n",
    "test your agent's strength against a set of known agents using tournament.py\n",
    "and include the results in your report.\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "\n",
    "class SearchTimeout(Exception):\n",
    "    \"\"\"Subclass base exception for code clarity. \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def custom_score(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    This should be the best heuristic function for your project submission.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    # This heuristic is an adjustment to the improved_score heuristic from the lectures whereby the agent's reward is \n",
    "    # weighted by the total number of available squares in the game. Early on this is high and player should try to \n",
    "    # limit their opponent's freedom to avoid being heavily penalised. As the endgame approaches, this agression factor \n",
    "    # decreases and the player is rewarded for staying out of trouble (keeping their own options open) \n",
    "    if game.is_loser(player):\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    if game.is_winner(player):\n",
    "        return float(\"inf\")\n",
    "\n",
    "    aggression = (len(game.get_legal_moves())) / 25\n",
    "    own_moves = len(game.get_legal_moves(player))\n",
    "    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(own_moves - aggression * opp_moves)\n",
    "    \n",
    "\n",
    "\n",
    "def custom_score_2(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "   \n",
    "    # This heuristic will try to force a board partition early on by awarding a high score to those boxes close to \n",
    "    # the main vertical and horizontal\n",
    "    if game.is_loser(player):\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    if game.is_winner(player):\n",
    "        return float(\"inf\")\n",
    "\n",
    "    w, h = game.width / 2., game.height / 2.\n",
    "    y, x = game.get_player_location(player)\n",
    "    return float(abs(h - y) + abs(w - x))\n",
    "    \n",
    "\n",
    "\n",
    "def custom_score_3(game, player):\n",
    "    \"\"\"Calculate the heuristic value of a game state from the point of view\n",
    "    of the given player.\n",
    "\n",
    "    Note: this function should be called from within a Player instance as\n",
    "    `self.score()` -- you should not need to call this function directly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : `isolation.Board`\n",
    "        An instance of `isolation.Board` encoding the current state of the\n",
    "        game (e.g., player locations and blocked cells).\n",
    "\n",
    "    player : object\n",
    "        A player instance in the current game (i.e., an object corresponding to\n",
    "        one of the player objects `game.__player_1__` or `game.__player_2__`.)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The heuristic value of the current game state to the specified player.\n",
    "    \"\"\"\n",
    "    \n",
    "    # This heuristic is an adjustment to the improved_score heuristic from the lectures whereby the agent's reward is \n",
    "    # weighted by an aggression factor that is close to 0 at the start of the game and close to 1 at the end of the game\n",
    "    # (essentially this is the opposite behaviour to custom_score function above). This means the agent is rewarded for\n",
    "    # keeping their moves open at the start (avoiding early isolation) and then at the end they are rewarded for \n",
    "    # aggressively trying to isolate their opponent.\n",
    "    if game.is_loser(player):\n",
    "        return float(\"-inf\")\n",
    "\n",
    "    if game.is_winner(player):\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    aggression = (25 - len(game.get_legal_moves())) / 25 \n",
    "    own_moves = len(game.get_legal_moves(player))\n",
    "    opp_moves = len(game.get_legal_moves(game.get_opponent(player)))\n",
    "    return float(own_moves - aggression * opp_moves)\n",
    "\n",
    "\n",
    "class IsolationPlayer:\n",
    "    \"\"\"Base class for minimax and alphabeta agents -- this class is never\n",
    "    constructed or tested directly.\n",
    "\n",
    "    ********************  DO NOT MODIFY THIS CLASS  ********************\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    search_depth : int (optional)\n",
    "        A strictly positive integer (i.e., 1, 2, 3,...) for the number of\n",
    "        layers in the game tree to explore for fixed-depth search. (i.e., a\n",
    "        depth of one (1) would only explore the immediate sucessors of the\n",
    "        current state.)\n",
    "\n",
    "    score_fn : callable (optional)\n",
    "        A function to use for heuristic evaluation of game states.\n",
    "\n",
    "    timeout : float (optional)\n",
    "        Time remaining (in milliseconds) when search is aborted. Should be a\n",
    "        positive value large enough to allow the function to return before the\n",
    "        timer expires.\n",
    "    \"\"\"\n",
    "    def __init__(self, search_depth=3, score_fn=custom_score, timeout=10.):\n",
    "        self.search_depth = search_depth\n",
    "        self.score = score_fn\n",
    "        self.time_left = None\n",
    "        self.TIMER_THRESHOLD = timeout\n",
    "\n",
    "\n",
    "class MinimaxPlayer(IsolationPlayer):\n",
    "    \"\"\"Game-playing agent that chooses a move using depth-limited minimax\n",
    "    search. You must finish and test this player to make sure it properly uses\n",
    "    minimax to return a good move before the search time limit expires.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_move(self, game, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "\n",
    "        **************  YOU DO NOT NEED TO MODIFY THIS FUNCTION  *************\n",
    "\n",
    "        For fixed-depth search, this function simply wraps the call to the\n",
    "        minimax method, but this method provides a common interface for all\n",
    "        Isolation agents, and you will replace it in the AlphaBetaPlayer with\n",
    "        iterative deepening search.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "        self.time_left = time_left\n",
    "\n",
    "        # Initialize the best move so that this function returns something\n",
    "        # in case the search fails due to timeout\n",
    "        best_move = (-1, -1)\n",
    "\n",
    "        try:\n",
    "            # The try/except block will automatically catch the exception\n",
    "            # raised when the timer is about to expire.\n",
    "            return self.minimax(game, self.search_depth)\n",
    "\n",
    "        except SearchTimeout:\n",
    "            pass  # Handle any actions required after timeout as needed\n",
    "\n",
    "        # Return the best move from the last completed search iteration\n",
    "        return best_move\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    def min_value(self, game, depth):\n",
    "        # Check for timeout in every call to helper functions \n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "        \n",
    "        # If no available moves then return the terminal utility/score\n",
    "        if not game.get_legal_moves():\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Once minimax has been recursively applied enough times the depth countdown hits zero and we return \n",
    "        # the utility/score at that particular depth limitation to then be propagated back up the tree\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Initially set v as worst possible result for MIN player then consider every possible move. As these moves\n",
    "        # backpropagate up a layer, the depth counter is reduced by 1 (terminates when hits zero) and the move we\n",
    "        # chose is passed to a MAX node. v is keeping track of our current BEST possible play by the MIN player\n",
    "        # and this should be updated to the minimum of the \"old v\" and the output of a MAX player's node that our\n",
    "        # previous MIN player's choice of move m fed into.\n",
    "        v = float('inf') \n",
    "        for m in game.get_legal_moves():\n",
    "            # Call board evaluation using self.score i.e. custom scoring\n",
    "            v = self.score(v, self.max_value(game.forecast_move(m), depth-1))\n",
    "        return v\n",
    "        \n",
    "    def max_value(self, game, depth):\n",
    "        # Check for timeout in every call to helper functions \n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "                \n",
    "        # If no available moves then return the terminal utility/score\n",
    "        if not game.get_legal_moves():\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Once minimax has been recursively applied enough times the depth countdown hits zero and we return \n",
    "        # the utility/score at that particular depth limitation to then be propagated back up the tree\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Initially set v as worst possible result for MAX player then consider every possible move. As these moves\n",
    "        # backpropagate up a layer, the depth counter is reduced by 1 (terminates when hits zero) and the move we\n",
    "        # chose is passed to a MIN node. v is keeping track of our current BEST possible play by the MAX player\n",
    "        # and this should be updated to the maximum of the \"old v\" and the output of a MIN player's node that our\n",
    "        # previous MAX player's choice of move m fed into.\n",
    "        for m in game.get_legal_moves():\n",
    "            # Call board evaluation using self.score i.e. custom scoring\n",
    "            v = self.score(v, self.min_value(game.forecast_move(m), depth-1))\n",
    "        return v\n",
    "        \n",
    "    def minimax(self, game, depth):\n",
    "    \"\"\"Implement depth-limited minimax search algorithm as described in\n",
    "    the lectures.\n",
    "\n",
    "    This should be a modified version of MINIMAX-DECISION in the AIMA text.\n",
    "    https://github.com/aimacode/aima-pseudocode/blob/master/md/Minimax-Decision.md\n",
    "\n",
    "    **********************************************************************\n",
    "    You MAY add additional methods to this class, or define helper\n",
    "          functions to implement the required functionality.\n",
    "    **********************************************************************\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    game : isolation.Board\n",
    "        An instance of the Isolation game `Board` class representing the\n",
    "        current game state\n",
    "\n",
    "    depth : int\n",
    "        Depth is an integer representing the maximum number of plies to\n",
    "        search in the game tree before aborting\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (int, int)\n",
    "        The board coordinates of the best move found in the current search;\n",
    "        (-1, -1) if there are no legal moves\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "        (1) You MUST use the `self.score()` method for board evaluation\n",
    "            to pass the project tests; you cannot call any other evaluation\n",
    "            function directly.\n",
    "\n",
    "        (2) If you use any helper functions (e.g., as shown in the AIMA\n",
    "            pseudocode) then you must copy the timer check into the top of\n",
    "            each helper function or else your agent will timeout during\n",
    "            testing.\n",
    "    \"\"\"\n",
    "    if self.time_left() < self.TIMER_THRESHOLD:\n",
    "        raise SearchTimeout()\n",
    "    \n",
    "    legal_moves = game.get_legal_moves()\n",
    "    best_score = float('-inf')\n",
    "    if not legal_moves:\n",
    "            return (-1, -1)\n",
    "    \n",
    "    best_move = legal_moves[0]\n",
    "    for m in legal_moves:\n",
    "        # Because we increment the depth below, we are instructing our agent to pick the move that will give our opponent\n",
    "        # (the MIN player) the highest score (worst for them and best for us). Assuming optimal play by both players this \n",
    "        # will then filter down the tree by the recurrent nature of our min and max helper functions (defined above) and \n",
    "        # ultimately give us the best possible score i.e. route/moves through the tree\n",
    "        score = self.min_value(game.forecast_move(m), depth-1)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_move = m\n",
    "    return m\n",
    "\n",
    "class AlphaBetaPlayer(IsolationPlayer):\n",
    "    \"\"\"Game-playing agent that chooses a move using iterative deepening minimax\n",
    "    search with alpha-beta pruning. You must finish and test this player to\n",
    "    make sure it returns a good move before the search time limit expires.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_move(self, game, time_left):\n",
    "        \"\"\"Search for the best move from the available legal moves and return a\n",
    "        result before the time limit expires.\n",
    "\n",
    "        Modify the get_move() method from the MinimaxPlayer class to implement\n",
    "        iterative deepening search instead of fixed-depth search.\n",
    "\n",
    "        **********************************************************************\n",
    "        NOTE: If time_left() < 0 when this function returns, the agent will\n",
    "              forfeit the game due to timeout. You must return _before_ the\n",
    "              timer reaches 0.\n",
    "        **********************************************************************\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        game : `isolation.Board`\n",
    "            An instance of `isolation.Board` encoding the current state of the\n",
    "            game (e.g., player locations and blocked cells).\n",
    "\n",
    "        time_left : callable\n",
    "            A function that returns the number of milliseconds left in the\n",
    "            current turn. Returning with any less than 0 ms remaining forfeits\n",
    "            the game.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (int, int)\n",
    "            Board coordinates corresponding to a legal move; may return\n",
    "            (-1, -1) if there are no available legal moves.\n",
    "        \"\"\"\n",
    "        self.time_left = time_left\n",
    "\n",
    "        # TODO: finish this function!\n",
    "        # Initialize the best move so that this function returns something\n",
    "        # in case the search fails due to timeout\n",
    "        best_move = (-1, -1)\n",
    "\n",
    "        try:\n",
    "            # The try/except block will automatically catch the exception\n",
    "            # raised when the timer is about to expire.\n",
    "            return self.alphabeta(game, self.search_depth)\n",
    "\n",
    "        except SearchTimeout:\n",
    "            pass  # Handle any actions required after timeout as needed\n",
    "\n",
    "        # Return the best move from the last completed search iteration\n",
    "        return best_move\n",
    "\n",
    "    \n",
    "        \n",
    "    def ab_max_value(self, game, depth, alpha, beta):\n",
    "        # Check for timeout in every call to helper functions \n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "          \n",
    "        # If no available moves then return the terminal utility/score\n",
    "        if not game.get_legal_moves():\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Once minimax has been recursively applied enough times the depth countdown hits zero and we return \n",
    "        # the utility/score at that particular depth limitation to then be propagated back up the tree\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Initially set v as worst possible result for MAX player then consider every possible move. As these moves\n",
    "        # backpropagate up a layer, the depth counter is reduced by 1 (terminates when hits zero) and the move we\n",
    "        # chose is passed to a MIN node. v is keeping track of our current BEST possible play by the MAX player\n",
    "        # and this should be updated to the maximum of the \"old v\" and the output of a MIN player's node that our\n",
    "        # previous MAX player's choice of move m fed into.\n",
    "        v = float('-inf') \n",
    "        for m in game.get_legal_moves():\n",
    "            # Call board evaluation using self.score i.e. custom scoring\n",
    "            v = self.score(v, self.ab_min_value(game.forecast_move(m), depth-1, alpha, beta))\n",
    "            # The alpha-beta bit is to check every possible move to see if it is greater than beta (the current\n",
    "            # worst performance for a MIN player). If it is then we should pick this as our choice for the MAX \n",
    "            # player. We then want to update alpha to be the maximum of this v and the old value of alpha as this\n",
    "            # now represents a guaranteed score that MAX can achieve and thus is our current estimate of the MAX\n",
    "            # player's worst possible performance (assuming no better moves lie ahead further down the tree).\n",
    "            if v >= beta:\n",
    "                return v\n",
    "                alpha = max(alpha, v)\n",
    "            return v\n",
    "    \n",
    "    def ab_min_value(self, game, depth, alpha, beta):\n",
    "        # Check for timeout in every call to helper functions \n",
    "        if self.time_left() < self.TIMER_THRESHOLD:\n",
    "            raise SearchTimeout()\n",
    "          \n",
    "        # If no available moves then return the terminal utility/score\n",
    "        if not game.get_legal_moves():\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Once minimax has been recursively applied enough times the depth countdown hits zero and we return \n",
    "        # the utility/score at that particular depth limitation to then be propagated back up the tree\n",
    "        if depth == 0:\n",
    "            return self.score(game, self)\n",
    "                \n",
    "        # Initially set v as worst possible result for MIN player then consider every possible move. As these moves\n",
    "        # backpropagate up a layer, the depth counter is reduced by 1 (terminates when hits zero) and the move we\n",
    "        # chose is passed to a MAX node. v is keeping track of our current BEST possible play by the MIN player\n",
    "        # and this should be updated to the maximum of the \"old v\" and the output of a MAX player's node that our\n",
    "        # previous MIN player's choice of move m fed into.\n",
    "        v = float('inf') \n",
    "        for m in game.get_legal_moves():\n",
    "            # Call board evaluation using self.score i.e. custom scoring\n",
    "            v = self.score(v, self.ab_max_value(game.forecast_move(m), depth-1, alpha, beta))\n",
    "            # The alpha-beta bit is to check every possible move to see if it is less than alpha (the current\n",
    "            # worst performance for a MAX player). If it is then we should pick this as our choice for the MIN \n",
    "            # player. We then want to update beta to be the maximum of this v and the old value of beta as this\n",
    "            # now represents a guaranteed score that MIN can achieve and thus is our current estimate of the MIN\n",
    "            # player's worst possible performance (assuming no better moves lie ahead further down the tree).\n",
    "            if v <= alpha:\n",
    "                return v\n",
    "                beta = min(beta, v)\n",
    "            return v\n",
    "    \n",
    "    def alphabeta(self, game, depth, alpha, beta):\n",
    "    \n",
    "    if self.time_left() < self.TIMER_THRESHOLD:\n",
    "        raise SearchTimeout()\n",
    "    \n",
    "    legal_moves = game.get_legal_moves()\n",
    "    best_score = float('-inf')\n",
    "    if not legal_moves:\n",
    "            return (-1, -1)\n",
    "    \n",
    "    best_move = legal_moves[0]\n",
    "    for m in legal_moves:\n",
    "        # Because we increment the depth below, we are instructing our agent to pick the move that will give our opponent\n",
    "        # (the MIN player) the highest score (worst for them and best for us). Assuming optimal play by both players this \n",
    "        # will then filter down the tree by the recurrent nature of our min and max helper functions (defined above) and \n",
    "        # ultimately give us the best possible score i.e. route/moves through the tree\n",
    "        score = self.min_value(game.forecast_move(m), depth-1)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_move = m\n",
    "        alpha = max(alpha, m)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aind]",
   "language": "python",
   "name": "conda-env-aind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
